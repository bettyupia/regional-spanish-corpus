---
title: "Term paper for crosslinguistic corpus linguistics"
author: "Claudia Beatriz Castillo Upiachihua, Student ID 7416549"
date: "2024-02-11"
output: 
  html_document:
    toc: true
bibliography: bibliography_citedrive.bib
---

# A corpus of Peruvian Spanish with a focus on word order

## I. Introduction

Every language is unique and serves as a window into the human cognition, culture, and society. A single language could contain features that other language may not. Yet, all languages serve the universal purpose of communication. The study of a language not only unravels the structure and patterns embedded within linguistic expressions but also sheds light on the diverse ways in which language is used and understood across different contexts and communities. Thus, if one wants to study a language, data of the language is needed.

Spanish is a language spoken by millions all over the world. It exhibits considerable diversity across different regions, influenced by historical, social, geographical, and linguistic contact. Each Spanish-speaking country, and even within countries, regions, or communities, may have distinct linguistic features, known as dialects. The linguistic variation of these dialects manifests in differences in vocabulary, pronunciation, grammar, discourse patterns, etc. Among the Spanish-speaking countries, Peru stands out as a compelling case study for investigating linguistic diversity and variation. Situated in the heart of South America, Peru boasts a rich tapestry of cultural and linguistic heritage, shaped by indigenous languages, colonial history, and other sociopolitical factors. Within Peru itself, linguistic diversity is further amplified by the presence of multiple indigenous languages alongside Spanish, as well as regional variations in Spanish dialects. The Andean Spanish of Peru is a great example of linguistic diversity and how a language can be shaped when two to more languages interact. The Andean Spanish has been greatly influenced by the indigenous languages of the region not only phonologically speaking but also grammatically. It is known that this dialect makes use of OV structures more frequently than the coastal dialect, which is a typical feature of Quechua and Aymara languages that are spoken in this region[@Klee2011].

In linguistics, the creation and analysis of corpora offer invaluable insights into the intricate nuances of language structure, variation, and usage. Therefore, I decided to create a corpus containing utterances from the coastal region of Peru, to be more specific from Lima as well as sentences from Cerro de Pasco which is an Andean Spanish dialect. Additionally, I will analyse the word order of sentences from the coastal and Andean Spanish and see if Andean speakers tend to produce more OV construction compared to the Lima dialect speakers. My idea in the beginning was to collect data from from 3 different regions of Peru, namely, data from the coastal, Andean and jungle dialect to then compare their different word orders. Nonetheless, there was not enough videos available online for this kind of research, especially from the Andean and jungle region.Then, I decided to focus on only 2 dialects. The main aim of this paper is to build a corpus using the spoken data from videos available in the web.The sentences will be annotated so that it will be easier to investigate different word order in Spanish.

### Research questions

-   RQ1. Do speakers of the andean dialect produce more OV compared to the coastal speakers?

-   RQ2. What word order is more frequent in both dialects?

We will focus on declarative sentences since some type of questions in Spanish change the order of its constituencies.

## II. Literature Review

The corpus approach has gain popularity in recent years as it is powerful methodology for analyzing different linguistic phenomena and linguistic variation. In this section, the importance of corpus-based studies to investigate linguistic phenomena will be highlighted, and a review of the literature on Peruvian Spanish word order will be provided as well.

Creating a corpus does not only involves collecting large bodies of text or speech, but also the annotation and analysis of this data, which helps to gain insights into language structure, usage, and variation [@biber1998]. Corpora serve as great and large resources for linguists, providing authentic language data that can be systematically examined to identify linguistic patterns and trends [@mcenery2019].

Regional corpora on the other hand play a crucial role in capturing the linguistic diversity and variation inherent within specific geographical contexts. By focusing on a particular region or dialect, unique linguistic features and language change can be revealed[@szmrecsanyi2017]. In the context of Peru, the coastal region exhibits a distinctive linguistic variety influenced by historical, social, and geographical factors. I will examine the distribution of word order in Peruvian coastal Spanish, But first it will be necessary to review existing literature on word order.

Spanish is a language that allows different positions of its constituencies. Although its canonical word order is SVO, it is more flexible than others SVO languages since its constituencies can have different positions within a sentence. The constituencies in a transitive sentences with a verb such as "Comprar" can take different places as the examples below taken from[@olarrea2012] paper. It might even seem like word order is rather free. However, some constituencies differ in order due to the discourse informational content, pragmatic functions, prosodic properties, such as new or previously mentioned information, and focus it wants to convey. And not all different word orders from the examples can be applied interchangeably within a specific discourse context. In other words, a sigle position of the elements provides information on its discourse context and or pragmatic function.

Examples from @olarrea2012

a\. (Él) compraba el periódico todos los días (SV0)

(He) used-to-buy the newspaper every day

b\. (Él) compraba todos los días el periódico(SVO)

c\. El perio´dico, (el) lo compraba todos los dias (OSV)

The newspaper, (he) cl-it used-to-buy everyday

d\. Él, el periódico lo compraba todos los días (SOV)

e\. El periódico lo compraba (él) todos los días (OVS)(OV)

f\. El periódico es lo que (él) compraba todos los días (OSV)(OV)

The newspaper is what (he) used-to-buy everyday

g\. El periódico es lo que compraba todos los días (él) (OVS) (OV)

h\. Compraba (él) el periódico todos los días (VSO)(VO)

i\. Todos los días compraba (él) el periódico.

One crucial property of Spanish is that the ordering of elements in a sentence reveals a particular information structure which is unique to that utterance. We can say that focus marking affects the structure of sentences, which often results in the alteration of the canonical SVO order. According to @ocampo1995, In standard Spanish the object-verb word order is pragmatically marked, and it is used to indicate a contrary to expectation function, contrast, focal constituent and topic. This word order occurs no so frequent in non-contact Spanish such as "limeño" Spanish. Another study by @KleeandOcampo that investigated the pragmatic functions of OV and VO constructions in Calca Spanish discovered that the speakers make use of the object-verb word order to express repetition, summary, agreement and explanation in addition to the previously mentioned pragmatic functions.

SVO is the canonical word order in Spanish. However When the subject is narrowly focused, it typically appears at the end of the sentence creating a VOS order. We can then say that focus marking affects the sentence structure, which often results in the alteration of the canonical SVO order(Domínguez2013)

## III. Methodology

### Data Collection

One of the first steps of this corpus creation was to find videos. I wanted to collect spoken naturalistic data from tiktok videos. It seemed to be an easy task. Just find any random videos and download them base on their regional accent. In fact, I spend quite long time trying to find these videos. Though, this was not the case of coastal Spanish videos. I found videos of people recommending restaurants, clothes, makeup and even activities that one can do during your free time. The hard part, however, was to find videos from andean and jungle people speaking Spanish. When searching for videos of recommendations of places in their regions, of restaurants or activities, only people speaking a coastal dialect appeared. I also found videos of these speakers explaining the way they speak. This was the case of both dialects. This, in my opinion, is not natural discourse and cannot be used to analyse the way people normally speak because in those videos they tend to exaggerate the way they speak and they will only say on or two sentences. The reason of this lack of videos might be due to the isolation of these communities.

As I encountered this problem, I decided to go out of the scope of Tiktok. YouTube seemed to be a great platform since there was more videos, especially interviews of people from Andean regions. These videos where mostly large videos of Andean people being interview and from Cerro the Pasco. (describe the place and mention other languages that are spoken in that place. From those videos only the parts where they were speaking were crop and each audio file has the utterances of a single speaker. After I found the videos on YouTube, I downloaded, cropped, and convert them into WAV files. As for the Tiktok videos (coastal dialect) it was not that difficult. Basically, my task was to download the videos and then convert them into WAV audio files. That way they were ready for transcription.

In total there are around 15 WAV files. There was 14 videos in the beginning, but one was added to match the amount of sentences per dialect.

### Transcription

The second step of the corpus creation was to transform spoken data into machine-readable text files. So that it will be easier to capture different linguistic phenomena. So first I created a visual studio project to work on the transcription part and also repository in Github to save, keep track and organize my work. The transformer model I used is called Whisper. The annotated code is available in my repository. When transcribing the videos using the Whisper(cite), the coastal videos were almost perfectly transcribe. However, the model could not identify the punctuation and therefore the sentence boundary was not clear. When a new sentences started, it will sometimes the first letter would be capital letter, but not always. naturally, I had to correct the sentences boundaries manually. In contrast, the transformer model did not detect the words produced by speakers of Cerro de Pasco as good as it did for the coastal "limeño" dialect. This might be due to the differences in pronunciation grammar and lexicon between them and because the model has not been trained with this dialect. As a result of the transcrption process, I opteained a csv file that will then be used for the next part.

### Annotation

A Corpus development has usually two major stages. The first one being data selection and processing. And that is what I have done until now (collection and transcription). The second stage is the annotation of this data. This stage is followed by the analysis if the data. For more details see Beck_et_al(2020). The type of annotation done in this Corpus is automatic annotation. Since it was sufficient to identify the word order, I didn't do any manual annotation.

In the beginning, I started importing the necessary libraries @qi2020stanza , uuid, os and setting the path where the output files would be stored. This was followed by a function to map the transcribed document into the format that can be saved and another function to help me to map the token generated by the Stanza. As final step, a pipeline was initialized

```{r libraries}
library(ggplot2)
library(dplyr)
```

```{r datasets}

# get dataframes of parsed sentences
# documents contain sentences and sentences contain tokens
# sentences$doc_id links with documents$id 
# tokens$sentence_id links with sentences$id

documents <- read.csv("../transcriber/output/parsed/documents.csv")
sentences <- read.csv("../transcriber/output/parsed/sentences.csv")
tokens <- read.csv("../transcriber/output/parsed/tokens.csv")

```

```{r get word order function}

# get word orders of each sentence
# the function carries out the following steps to generate word order:
# 1. iterate all given sentences
# 2. iterate all verb tokens in each sentence
# 3. get the 'nsubj' and 'obj' children from the dependency parsing result
#    where 'head' column in tokens refer to its parent token index
#    and 'deprel' refer to its relationship
# 4. comparing the indices of nsubj(may not be present), obj and the verb


# return a dataframe contains:
# 1. word order in form of 'S', 'V', 'O' concatenated string
# 2. the verb, the sentence and the document where the word order is presented
get_sentences_word_order <- function(sentences_in) {
  
  # initialize dataframe to store the result
  word_orders <- tibble(
    doc_id=character(),
    doc_title=character(),
    sentence_id=character(),
    sentence_index=character(),
    verb_id=character(),
    verb_index=character(),
    word_order=character(), 
    dialect=character())
  
    for (i in 1:nrow(sentences_in)) {
      sentence <- sentences_in[i, ]
      # get document where the sentence is from
      document <- (documents %>% filter(id == sentence$doc_id))[1, ]
      
      # filter tokens that belong to the sentence
      sentence_tokens <- tokens %>% filter(sentence_id == sentence$id)
    
      # filter only verb tokens
      sentence_verb_tokens <- sentence_tokens %>% filter(upos == 'VERB')
      
      # make sure there exist verbs in the sentence
      # this step is necessary because 1:0 in R gives c(1, 0) which should be empty
      if (nrow(sentence_verb_tokens) > 0) {
        
        for (i in 1:nrow(sentence_verb_tokens)) {
          
          # get verb
          verb <- sentence_verb_tokens[i, ]
          
          # get nsubj children
          nsubj <- sentence_tokens %>% filter(head == verb$index & deprel == 'nsubj')
          # get obj children
          obj <- sentence_tokens %>% filter(head == verb$index & deprel == 'obj')
          
          # in case of no nsubj and one obj presents
          # VO or OV
          if (nrow(nsubj) == 0 & nrow(obj) == 1) {
            
            # create named vector with S/V/O as names and their token indices as value
            word_order_pos <- c('v' = verb$index, 'o' = obj[1, ]$index)
            
            # sort by indices then get names
            sorted_word_order <- names(sort(word_order_pos))
            
            # concatenate
            word_order <- paste(sorted_word_order, collapse = '')
            
            # store the result
            word_orders <- word_orders %>%  add_row(
              doc_id=document$id,
              doc_title=document$title,
              sentence_id=sentence$id,
              sentence_index=as.character(sentence$index),
              verb_id=verb$id,
              verb_index=verb$index,
              word_order=word_order,
              dialect=document$dialect)
            
          } 
          else if (nrow(nsubj) == 1 & nrow(obj) == 1) 
          {
            # in case of one nsubj and one obj present
            # all combination of 'S', 'V', 'O', e.g. SVO
            word_order_pos <- c('s' = nsubj[1, ]$index, 'v' = verb$index, 'o' = obj[1, ]$index)
            
            # the following steps are identical with the obj only case above
            sorted_word_order <- names(sort(word_order_pos))
            word_order <- paste(sorted_word_order, collapse = '')
            word_orders <- word_orders %>%  add_row(
              doc_id=document$id,
              doc_title=document$title,
              sentence_id=sentence$id,
              sentence_index=as.character(sentence$index),
              verb_id=verb$id,
              verb_index=verb$index,
              word_order=word_order,
              dialect=document$dialect)
          }
        }
      }
    }
  
    return(word_orders)

}
```

## IV. Data analysis

I found an abnormal osv in the bar plot. There was only one sentence from the andean dialect. I went to check that by searching the sentence ID and verb index and noticed that there were two sentences instead of one. The tokenizer could not detect the correct word order because of that. So I will separate the to sentences so that the tokenizer give me the correct data.

```{r get affirmative sentence ids}
# filter the sentence without '?' token
affirmative_sentence_ids <- (tokens %>% group_by(sentence_id) %>% filter(!any(text == '?')) %>% summarise())$sentence_id
```

```{r}
# check if andean and costal have similar number of sentences
print('Total sentence count in the two dialect categories')
left_join(sentences, documents %>% rename(doc_id = id), by = "doc_id") %>%
  group_by(dialect) %>% 
  summarise(count = n())

# # check if andean and costal have similar number of affirmative sentences 
print('Affirmative sentence count in the two dialect categories')
left_join(sentences, documents %>% rename(doc_id = id), by = "doc_id") %>%
  filter(id %in% affirmative_sentence_ids) %>%
  group_by(dialect) %>% 
  summarise(count = n())

```

```{r word order for all sentences by dialect}
# plot count of word orders in the two dialect groups as bar plot
get_sentences_word_order(sentences) %>%
  group_by(dialect, word_order) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = word_order, y = count, fill = dialect)) + 
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  labs(x = "Word Order", y = "Count",
       title = "Word Orders for All Sentences by Dialects")
```

```{r word order for affirmative sentences by dialect}
affirmative_sentences <- sentences %>% filter(id %in% affirmative_sentence_ids)

get_sentences_word_order(affirmative_sentences) %>%
  group_by(dialect, word_order) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = word_order, y = count, fill = dialect)) + 
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  labs(x = "Word Order", y = "Count",
       title = "Word Orders for Affirmative Sentences by Dialects")

```

## V. Discussion

## VI. Conclusion

## References
