# -*- coding: utf-8 -*-
"""ASR-Whisper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ppX5h_70Wg38yBX3Swff6AUbGXEkbohy

A good tutorial on how to use Whisper for automatic transcription

https://machinelearningknowledge.ai/openai-whisper-tutorial-both-api-and-open-source/
"""

# !pip install -qq openai

# pip install git+https://github.com/openai/whisper.git

# You need to generate an openai key and provide it here
import openai
openai.api_key = "YOUR-API-KEY-HERE"

import whisper

model = whisper.load_model("base") # there are different models to load. I've loaded the base model.

#loading audio file
audio = whisper.load_audio("1.wav")

#transcribing the file.

result = model.transcribe(audio)

print(result["text"])